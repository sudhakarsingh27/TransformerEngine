{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc0aeca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip list | grep torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b12a92c",
   "metadata": {},
   "source": [
    "### Import the libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77990436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "someone called API registrations\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformer_engine.pytorch as te\n",
    "from transformer_engine.common import recipe\n",
    "import numpy as np\n",
    "from transformer_engine.pytorch import Float8Tensor, E4M3, tensor_to_scale\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3084af",
   "metadata": {},
   "source": [
    "### Create the model as a single TE.Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd1e75b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before parameter init\n",
      "aten.detach.default\n",
      "aten.detach.default\n",
      "after parameter init\n",
      "after register param\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.14) or chardet (5.1.0)/charset_normalizer (3.1.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "# Set dimensions.\n",
    "in_features = 16\n",
    "out_features = 16\n",
    "hidden_size = 16\n",
    "\n",
    "model = te.Linear(in_features, out_features, bias=False, params_dtype=torch.float32)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697c6257",
   "metadata": {},
   "source": [
    "### Single iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e14a108c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1808, -0.5523,  0.9238, -0.7350,  1.3800,  0.8676,  0.1297, -0.9406,\n",
      "         0.8109,  0.8821, -1.0133, -0.3634,  0.5101,  0.4179, -0.6888, -0.1347],\n",
      "       device='cuda:0')\n",
      "{'fp8_group': None, 'recipe': DelayedScaling(margin=0, interval=1, fp8_format=<Format.HYBRID: _FormatHelper(max_fwd=448, max_bwd=57344)>, amax_history_len=1024, amax_compute_algo='max', override_linear_precision=_OverrideLinearPrecision(fprop=False, dgrad=False, wgrad=False), scaling_factor_compute_algo=None, reduce_amax=True), 'autocast_id_fwd_stack': [], 'async_amax_reduction': False}\n",
      "None\n",
      "fp8.py:  tensor([0., 0.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "inp = torch.randn(hidden_size, in_features, device=\"cuda\")\n",
    "print(inp[0])\n",
    "# Create an FP8 recipe. Note: All input args are optional.\n",
    "fp8_recipe = recipe.DelayedScaling(margin=0, interval=1, fp8_format=recipe.Format.E4M3)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "# Enable autocasting for the forward pass\n",
    "with te.fp8_autocast(enabled=True, fp8_recipe=fp8_recipe):\n",
    "    print(model.fp8_meta)\n",
    "    out = model(inp, is_first_microbatch=None)\n",
    "\n",
    "loss = out.sum()\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b12d304",
   "metadata": {},
   "source": [
    "### Check scales "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "497c1ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1.], device='cuda:0') tensor(5874.6479, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(model.fp8_meta['scaling_fwd'].scale, model.weight._scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b859bb",
   "metadata": {},
   "source": [
    "### Check `amax_history`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18c03ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([0]), array([0])), array([3.0268958], dtype=float32))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a_h_flat = model.fp8_meta['scaling_fwd'].amax_history.cpu().numpy().flatten()\n",
    "a_h_flat = model.fp8_meta['scaling_fwd'].amax_history.cpu().numpy() #[1024,3]\n",
    "np.where(a_h_flat > 0.0), a_h_flat[a_h_flat > 0.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbd6ce0",
   "metadata": {},
   "source": [
    "### Do 1 optimizer step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5b809cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aten.add_.Tensor\n"
     ]
    }
   ],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6c0d7e",
   "metadata": {},
   "source": [
    "### Check scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5d32514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale info:  tensor([1., 1., 1.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"scale info: \", model.fp8_meta['scaling_fwd'].scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b9ac9c",
   "metadata": {},
   "source": [
    "### Check amax history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b54a85a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([0, 0]), array([0, 1])), array([3.0268958, 4.9162116], dtype=float32))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a_h_flat = model.fp8_meta['scaling_fwd'].amax_history.cpu().numpy().flatten()\n",
    "a_h_flat = model.fp8_meta['scaling_fwd'].amax_history.cpu().numpy() #[1024,3]\n",
    "np.where(a_h_flat > 0.0), a_h_flat[a_h_flat > 0.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1082ec4f",
   "metadata": {},
   "source": [
    "### Do subsequent iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "803412f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fp8.py:  tensor([3.0269, 0.0000, 0.0000], device='cuda:0')\n",
      "after amax scale update\n",
      "None\n",
      "fp8.py:  tensor([1., 0.], device='cuda:0')\n",
      "scale info:  tensor([128.,   1.,   1.], device='cuda:0')\n",
      "fp8.py:  tensor([3.6680, 0.0000, 0.0000], device='cuda:0')\n",
      "after amax scale update\n",
      "None\n",
      "fp8.py:  tensor([1., 0.], device='cuda:0')\n",
      "scale info:  tensor([64.,  1.,  1.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for _ in range(2):\n",
    "    inp = torch.randn(hidden_size, in_features, device=\"cuda\")\n",
    "    # print(inp[0])\n",
    "\n",
    "    # Enable autocasting for the forward pass\n",
    "    with te.fp8_autocast(enabled=True, fp8_recipe=fp8_recipe):\n",
    "        out = model(inp, is_first_microbatch=None)\n",
    "\n",
    "    loss = out.sum()\n",
    "    loss.backward()\n",
    "\n",
    "    # print the scaling information\n",
    "    print(\"scale info: \", model.fp8_meta['scaling_fwd'].scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50f858df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([64.,  1.,  1.], device='cuda:0') tensor(5874.6479, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(model.fp8_meta['scaling_fwd'].scale, model.weight._scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50afa08c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([   0, 1022, 1023]), array([0, 0, 0])),\n",
       " array([3.8595376, 3.0268958, 3.668017 ], dtype=float32))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a_h_flat = model.fp8_meta['scaling_fwd'].amax_history.cpu().numpy().flatten()\n",
    "a_h_flat = model.fp8_meta['scaling_fwd'].amax_history.cpu().numpy()\n",
    "np.where(a_h_flat > 0.0), a_h_flat[a_h_flat > 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a31bc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
